import urllib.request
import pandas as pd
import os, os.path
import glob
import requests
import datetime

main_folder = "D:\Python\Lab1\collected_data"

changedIndex = {1:24, 2:25, 3:5, 4:6, 5:27, 6:23, 7:26, 8:7, 9:11, 10:13, 11:14, 12:15, 13:16, 14:17, 15:18, 16:19, 17:21,
        18:22, 19:8, 20:9, 21:10, 22:1, 23:3, 24:2, 25:4, 26:12, 27:20}

def clean_data(directory, index):
    os.chdir(directory)
    for file in glob.glob(os.path.join(directory, "province{}*.csv".format(index))):
        os.remove(file)

def prepare_data(line):
    if 'UKR' in line:
        return ''
    line = line.replace(' ', ',',2)
    return (line + '\n')

def download_data(directory, index, minYear=1991, maxYear=2020):
    url = "https://www.star.nesdis.noaa.gov/smcd/emb/vci/VH/get_provinceData.php?country=UKR&provinceID={}&year1={}&year2={}&type=Mean".format(changedIndex[index], minYear, maxYear)
    response = requests.get(url)
    path = os.path.join(directory, "province{}_{}.csv".format(index, datetime.datetime.today().strftime("%d-%m-%Y_%H-%M")))
    with open(path, 'w') as file:
        file.write("Year,Week,SMN,SMT,VCI,TCI,VHI\n")
        for line in response.iter_lines(chunk_size=512, decode_unicode=True):
            file.write(line)
            #file.write(prepare_data(line))

def download_all():
    for i in range (1, 28):
        clean_data(main_folder, i)
        download_data(main_folder, i)
        print ("Province {} is ready to use.".format(i))

#https://www.star.nesdis.noaa.gov/smcd/emb/vci/VH/get_TS_admin.php?country=UKR&provinceID=24&year1=1981&year2=2020&type=Mean
#https://www.star.nesdis.noaa.gov/smcd/emb/vci/VH/get_TS_admin.php?country=UKR&provinceID=18&year1=1981&year2=2020&type=Mean
#https://www.star.nesdis.noaa.gov/smcd/emb/vci/VH/get_provinceData.php?country=UKR&provinceID={}&year1={}&year2={}&type=Mean
